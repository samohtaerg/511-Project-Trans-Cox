# -*- coding: utf-8 -*-
"""Seer Data EDA

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X3nhSCl38ZxXX6g9cXZPy0zuFnkWjWRB
"""

!pip install lifelines
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from lifelines import CoxPHFitter
from lifelines.utils import concordance_index
from google.colab import drive
drive.mount('/content/drive')

"""## Seer Overview

"""

# Read the data
path = '/content/drive/My Drive/Kernel Real Data/seer_breast.csv'
df = pd.read_csv(path, sep=',')

print("="*80)
print("SEER Breast Cancer Dataset - Variable Information")
print("="*80)
print(f"Dataset shape: {df.shape}")
print(f"Number of rows: {df.shape[0]:,}")
print(f"Number of columns: {df.shape[1]}")

print("\n" + "="*80)
print("All Variables Overview")
print("="*80)

# Print all column names with index
print("Column names:")
for i, col in enumerate(df.columns):
    print(f"{i+1:2d}. {col}")

print("\n" + "="*80)
print("Data Types")
print("="*80)

# Print data types
print("Data types for each variable:")
for i, (col, dtype) in enumerate(df.dtypes.items()):
    print(f"{i+1:2d}. {col:<50} : {dtype}")

print("\n" + "="*80)
print("Basic Information for Each Variable")
print("="*80)

# For each column, show basic info
for i, col in enumerate(df.columns):
    print(f"\n{i+1}. Variable: {col}")
    print(f"   Data type: {df[col].dtype}")
    print(f"   Non-null count: {df[col].count():,}")
    print(f"   Null count: {df[col].isnull().sum():,}")
    print(f"   Unique values: {df[col].nunique():,}")

    # Show first few unique values
    unique_vals = df[col].unique()
    if len(unique_vals) <= 10:
        print(f"   All unique values: {list(unique_vals)}")
    else:
        print(f"   First 5 unique values: {list(unique_vals[:5])}")
        print(f"   Last 5 unique values: {list(unique_vals[-5:])}")

    print("-" * 60)

print("\n" + "="*80)
print("Summary Statistics")
print("="*80)

# Try to show summary statistics for numeric-like columns
print("Attempting to show summary statistics:")
print(df.describe(include='all'))

"""## Data Cleaning

"""

# Initialize the cleaned dataframe
df_clean = pd.DataFrame()

print("\n" + "="*60)
print("1. Age Transformation")
print("="*60)

def transform_age(age_series):
    """Transform age from '64 years' format to integer"""
    age_numeric = []
    for age_str in age_series:
        if pd.isna(age_str):
            age_numeric.append(np.nan)
        elif '90+' in str(age_str):
            age_numeric.append(90)  # Treat 90+ as 90
        else:
            # Extract number from string like '64 years'
            try:
                age_num = int(str(age_str).split()[0])
                age_numeric.append(age_num)
            except:
                age_numeric.append(np.nan)
    return pd.Series(age_numeric)

df_clean['age'] = transform_age(df['Age recode with single ages and 90+'])
print(f"Age range: {df_clean['age'].min():.0f} - {df_clean['age'].max():.0f}")
print(f"Age mean: {df_clean['age'].mean():.1f}")
print(f"Missing age values: {df_clean['age'].isna().sum()}")

print("\n" + "="*60)
print("2. Survival Time Transformation")
print("="*60)

def transform_survival_months(survival_series):
    """Transform survival months from '0162' format to integer"""
    survival_numeric = pd.to_numeric(survival_series, errors='coerce')
    return survival_numeric

df_clean['survival_months'] = transform_survival_months(df['Survival months'])
print(f"Survival time range: {df_clean['survival_months'].min():.0f} - {df_clean['survival_months'].max():.0f} months")
print(f"Survival time mean: {df_clean['survival_months'].mean():.1f} months")
print(f"Missing survival values: {df_clean['survival_months'].isna().sum()}")

print("\n" + "="*60)
print("3. Cancer Death Event Transformation")
print("="*60)

def transform_cancer_death(death_classification):
    """Transform SEER cause-specific death to binary event indicator"""
    cancer_death = (death_classification == 'Dead (attributable to this cancer dx)').astype(int)
    return cancer_death

df_clean['cancer_death'] = transform_cancer_death(df['SEER cause-specific death classification'])
print("Cancer death distribution:")
print(df_clean['cancer_death'].value_counts())
cancer_death_rate = df_clean['cancer_death'].mean() * 100
print(f"Cancer death rate: {cancer_death_rate:.1f}%")

print("\n" + "="*60)
print("4. Vital Status Transformation")
print("="*60)

def transform_vital_status(vital_series):
    """Transform vital status to binary (1=Dead, 0=Alive)"""
    vital_status = (vital_series == 'Dead').astype(int)
    return vital_status

df_clean['vital_status'] = transform_vital_status(df['Vital status recode (study cutoff used)'])
print("Vital status distribution:")
print(df_clean['vital_status'].value_counts())
overall_death_rate = df_clean['vital_status'].mean() * 100
print(f"Overall death rate: {overall_death_rate:.1f}%")

print("\n" + "="*60)
print("5. CS Tumor Size Transformation")
print("="*60)

def transform_cs_tumor_size(cs_series):
    """Transform CS tumor size to numeric mm and availability indicator

    SEER CS Tumor Size Codes:
    000: No evidence of primary tumor
    001-400: 0.1cm to 40.0cm (actual size in mm)
    990: Microscopic focus
    998: Site-specific code
    999: Unknown or unreasonable size (includes 401-989)
    """
    tumor_size = []
    has_cs_data = []

    for size_str in cs_series:
        if str(size_str) == 'Blank(s)':
            tumor_size.append(np.nan)
            has_cs_data.append(0)
        else:
            try:
                size_code = int(str(size_str))
                has_cs_data.append(1)  # Has CS data

                if size_code == 0:
                    # No evidence of primary tumor
                    tumor_size.append(0.0)
                elif 1 <= size_code <= 400:
                    # Valid size: 0.1cm to 40.0cm
                    tumor_size.append(float(size_code))
                elif size_code == 990:
                    # Microscopic focus - assign small value
                    tumor_size.append(0.5)
                elif size_code in [998, 999] or (401 <= size_code <= 989):
                    # Unknown size or unreasonable size (401-989 are coded as 999)
                    tumor_size.append(np.nan)
                else:
                    # Any other unexpected code
                    tumor_size.append(np.nan)

            except ValueError:
                tumor_size.append(np.nan)
                has_cs_data.append(0)

    return pd.Series(tumor_size), pd.Series(has_cs_data)

df_clean['tumor_size_mm'], df_clean['has_cs_data'] = transform_cs_tumor_size(df['CS tumor size (2004-2015)'])
print(f"CS data available: {df_clean['has_cs_data'].sum():,} ({df_clean['has_cs_data'].mean()*100:.1f}%)")

# Analyze CS tumor size data
cs_data = df_clean[df_clean['has_cs_data'] == 1]['tumor_size_mm']
cs_valid = cs_data.dropna()  # Remove unknown sizes (999, 998, 401-989 codes)

print(f"CS cases with known tumor size: {len(cs_valid):,} ({len(cs_valid)/df_clean['has_cs_data'].sum()*100:.1f}% of CS cases)")
if len(cs_valid) > 0:
    print(f"Tumor size range (valid): {cs_valid.min():.1f} - {cs_valid.max():.1f} mm")
    print(f"Tumor size mean (valid): {cs_valid.mean():.1f} mm")
    print(f"Tumor size median (valid): {cs_valid.median():.1f} mm")

    # Show distribution
    print(f"Size distribution:")
    print(f"  0mm (no tumor): {(cs_valid == 0).sum():,}")
    print(f"  0.1-20mm (≈T1): {((cs_valid > 0) & (cs_valid <= 20)).sum():,}")
    print(f"  21-50mm (≈T2): {((cs_valid > 20) & (cs_valid <= 50)).sum():,}")
    print(f"  >50mm (≈T3+): {(cs_valid > 50).sum():,}")

cs_unknown = cs_data.isna().sum()
print(f"CS cases with unknown tumor size: {cs_unknown:,} ({cs_unknown/df_clean['has_cs_data'].sum()*100:.1f}% of CS cases)")
print("Note: Unknown sizes include SEER codes 998, 999, and 401-989 (unreasonable sizes)")

print("\n" + "="*60)
print("6. EOD T-Stage Transformation")
print("="*60)

def transform_eod_to_tstage(eod_series):
    """Transform EOD codes to T-stage (0-4) and availability indicator"""
    t_stage = []
    has_eod_data = []

    # EOD to T-stage mapping
    eod_mapping = {
        '000': 0,  # Tis - carcinoma in situ
        '050': 1, '070': 1, '100': 1,  # T1 - ≤20mm
        '200': 2,  # T2 - 20-50mm
        '400': 3,  # T3 - >50mm
        '450': 4, '575': 4,  # T4 - local invasion
    }

    for eod_str in eod_series:
        if str(eod_str) == 'Blank(s)':
            t_stage.append(np.nan)
            has_eod_data.append(0)
        elif str(eod_str) == '999':  # Unknown
            t_stage.append(np.nan)
            has_eod_data.append(1)  # Has EOD data but unknown
        elif str(eod_str) in eod_mapping:
            t_stage.append(eod_mapping[str(eod_str)])
            has_eod_data.append(1)
        else:
            t_stage.append(np.nan)
            has_eod_data.append(1)

    return pd.Series(t_stage), pd.Series(has_eod_data)

df_clean['t_stage'], df_clean['has_eod_data'] = transform_eod_to_tstage(df['EOD Primary Tumor (2018+)'])
print(f"EOD data available: {df_clean['has_eod_data'].sum():,} ({df_clean['has_eod_data'].mean()*100:.1f}%)")
if df_clean['t_stage'].notna().sum() > 0:
    print("T-stage distribution:")
    print(df_clean['t_stage'].value_counts().sort_index())

print("\n" + "="*60)
print("7. Regional Lymph Nodes Transformation")
print("="*60)

def transform_lymph_nodes_positive(nodes_series):
    """Transform regional nodes positive based on SEER coding manual:
    00: All nodes examined are negative
    01-89: Exact number of nodes positive
    90: 90 or more nodes are positive
    95: Positive aspiration of lymph node(s) was performed
    97: Positive nodes are documented, but number is unspecified
    98: No nodes were examined
    99: Unknown whether nodes are positive; not applicable; not stated
    """
    nodes_numeric = []
    nodes_known = []

    for node_str in nodes_series:
        if str(node_str) == 'Blank(s)':
            nodes_numeric.append(np.nan)
            nodes_known.append(0)
        else:
            try:
                node_code = int(str(node_str))

                if node_code == 0:
                    # All nodes negative
                    nodes_numeric.append(0)
                    nodes_known.append(1)
                elif 1 <= node_code <= 89:
                    # Exact number of positive nodes
                    nodes_numeric.append(node_code)
                    nodes_known.append(1)
                elif node_code == 90:
                    # 90 or more positive
                    nodes_numeric.append(90)
                    nodes_known.append(1)
                elif node_code in [95, 97, 98, 99]:
                    # Various forms of unknown
                    nodes_numeric.append(np.nan)
                    nodes_known.append(0)
                else:
                    # Unexpected code
                    nodes_numeric.append(np.nan)
                    nodes_known.append(0)

            except ValueError:
                nodes_numeric.append(np.nan)
                nodes_known.append(0)

    return pd.Series(nodes_numeric), pd.Series(nodes_known)

def transform_lymph_nodes_examined(nodes_series):
    """Transform regional nodes examined with similar logic"""
    nodes_numeric = []
    nodes_known = []

    for node_str in nodes_series:
        if str(node_str) == 'Blank(s)':
            nodes_numeric.append(np.nan)
            nodes_known.append(0)
        else:
            try:
                node_code = int(str(node_str))

                if 0 <= node_code <= 89:
                    # Valid number examined
                    nodes_numeric.append(node_code)
                    nodes_known.append(1)
                elif node_code == 90:
                    # 90 or more examined
                    nodes_numeric.append(90)
                    nodes_known.append(1)
                elif node_code in [95, 97, 98, 99]:
                    # Various forms of unknown
                    nodes_numeric.append(np.nan)
                    nodes_known.append(0)
                else:
                    nodes_numeric.append(np.nan)
                    nodes_known.append(0)

            except ValueError:
                nodes_numeric.append(np.nan)
                nodes_known.append(0)

    return pd.Series(nodes_numeric), pd.Series(nodes_known)

# Transform positive nodes with correct SEER codes
df_clean['nodes_positive'], df_clean['nodes_positive_known'] = transform_lymph_nodes_positive(
    df['Regional nodes positive (1988+)']
)

# Transform examined nodes with correct SEER codes
df_clean['nodes_examined'], df_clean['nodes_examined_known'] = transform_lymph_nodes_examined(
    df['Regional nodes examined (1988+)']
)

print(f"Positive nodes data available: {df_clean['nodes_positive_known'].sum():,} ({df_clean['nodes_positive_known'].mean()*100:.1f}%)")
print(f"Examined nodes data available: {df_clean['nodes_examined_known'].sum():,} ({df_clean['nodes_examined_known'].mean()*100:.1f}%)")

if df_clean['nodes_positive_known'].sum() > 0:
    pos_data = df_clean[df_clean['nodes_positive_known'] == 1]['nodes_positive']
    print(f"Positive nodes range: {pos_data.min():.0f} - {pos_data.max():.0f}")
    print(f"Positive nodes mean: {pos_data.mean():.1f}")
    print(f"Node-negative (0): {(pos_data == 0).sum():,} ({(pos_data == 0).mean()*100:.1f}%)")
    print(f"1-3 positive: {((pos_data >= 1) & (pos_data <= 3)).sum():,} ({((pos_data >= 1) & (pos_data <= 3)).mean()*100:.1f}%)")
    print(f"4-9 positive: {((pos_data >= 4) & (pos_data <= 9)).sum():,} ({((pos_data >= 4) & (pos_data <= 9)).mean()*100:.1f}%)")
    print(f"10+ positive: {(pos_data >= 10).sum():,} ({(pos_data >= 10).mean()*100:.1f}%)")

if df_clean['nodes_examined_known'].sum() > 0:
    exam_data = df_clean[df_clean['nodes_examined_known'] == 1]['nodes_examined']
    print(f"Examined nodes range: {exam_data.min():.0f} - {exam_data.max():.0f}")
    print(f"Examined nodes mean: {exam_data.mean():.1f}")

print("\n" + "="*60)
print("8. Treatment Timing Transformation")
print("="*60)

def transform_treatment_timing(timing_series):
    """Transform days to treatment to numeric and availability indicator"""
    days_numeric = []
    timing_known = []

    for timing_str in timing_series:
        if str(timing_str) == 'Unable to calculate':
            days_numeric.append(np.nan)
            timing_known.append(0)
        else:
            try:
                days_num = int(str(timing_str))
                days_numeric.append(days_num)
                timing_known.append(1)
            except:
                days_numeric.append(np.nan)
                timing_known.append(0)

    return pd.Series(days_numeric), pd.Series(timing_known)

df_clean['days_to_treatment'], df_clean['treatment_timing_known'] = transform_treatment_timing(
    df['Time from diagnosis to treatment in days recode']
)

print(f"Treatment timing data available: {df_clean['treatment_timing_known'].sum():,} ({df_clean['treatment_timing_known'].mean()*100:.1f}%)")
if df_clean['treatment_timing_known'].sum() > 0:
    timing_data = df_clean[df_clean['treatment_timing_known'] == 1]['days_to_treatment']
    print(f"Days to treatment range: {timing_data.min():.0f} - {timing_data.max():.0f}")
    print(f"Days to treatment mean: {timing_data.mean():.1f}")

print("\n" + "="*60)
print("9. Create Composite Variables")
print("="*60)

# Nodes data completeness
df_clean['nodes_data_complete'] = (
    (df_clean['nodes_positive_known'] == 1) &
    (df_clean['nodes_examined_known'] == 1)
).astype(int)

print(f"Complete lymph node data: {df_clean['nodes_data_complete'].sum():,} ({df_clean['nodes_data_complete'].mean()*100:.1f}%)")

# Create era indicators
df_clean['era_cs'] = df_clean['has_cs_data']
df_clean['era_eod'] = df_clean['has_eod_data']

print(f"CS era patients: {df_clean['era_cs'].sum():,}")
print(f"EOD era patients: {df_clean['era_eod'].sum():,}")
print(f"Both CS and EOD: {((df_clean['era_cs'] == 1) & (df_clean['era_eod'] == 1)).sum():,}")


##Add the position information
df_clean['primary_site'] = df['Primary Site - labeled']
print("\n" + "="*80)
print("FINAL TRANSFORMED DATASET SUMMARY")
print("="*80)


print("\n" + "="*80)
print("FINAL TRANSFORMED DATASET SUMMARY")
print("="*80)

print(f"Final dataset shape: {df_clean.shape}")
print(f"Original variables: {df.shape[1]} → Final variables: {df_clean.shape[1]}")

print("\nFinal variable list:")
for i, col in enumerate(df_clean.columns, 1):
    dtype = df_clean[col].dtype
    missing = df_clean[col].isna().sum()
    missing_pct = missing / len(df_clean) * 100
    print(f"{i:2d}. {col:<25} | {str(dtype):<7} | Missing: {missing:>6,} ({missing_pct:>5.1f}%)")

print("\nData types summary:")
print(df_clean.dtypes.value_counts())

print("\nCore survival analysis variables:")
print("- Time variable: survival_months")
print("- Event variable: cancer_death")
print("- Key covariates: age, tumor_size_mm, t_stage, nodes_positive, nodes_examined")

print(f"\nDataset ready for survival analysis!")
print(f"Recommended next step: Remove rows with missing survival_months or cancer_death")

# Show a few sample rows
print(f"\nSample of transformed data:")
print(df_clean.head())

# Modified SEER Analysis - Including Primary Site Analysis
import pandas as pd
import numpy as np
from lifelines import CoxPHFitter
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming df_clean exists from your original code
# Add primary site transformation to your existing data cleaning

print("="*80)
print("ADDING PRIMARY SITE ANALYSIS TO EXISTING SEER DATA")
print("="*80)

def transform_primary_site(site_series):
    """Transform primary site to simplified categories"""
    site_clean = []
    site_codes = []

    for site in site_series:
        if 'Upper-outer quadrant' in site:
            site_clean.append('UOQ')
            site_codes.append('C50.4')
        elif 'Upper-inner quadrant' in site:
            site_clean.append('UIQ')
            site_codes.append('C50.2')
        elif 'Lower-outer quadrant' in site:
            site_clean.append('LOQ')
            site_codes.append('C50.5')
        elif 'Lower-inner quadrant' in site:
            site_clean.append('LIQ')
            site_codes.append('C50.3')
        elif 'Central portion' in site:
            site_clean.append('Central')
            site_codes.append('C50.1')
        elif 'Nipple' in site:
            site_clean.append('Nipple')
            site_codes.append('C50.0')
        elif 'Axillary tail' in site:
            site_clean.append('Axillary')
            site_codes.append('C50.6')
        elif 'Overlapping lesion' in site:
            site_clean.append('Overlapping')
            site_codes.append('C50.8')
        elif 'NOS' in site:
            site_clean.append('NOS')
            site_codes.append('C50.9')
        else:
            site_clean.append('Unknown')
            site_codes.append('Unknown')

    return pd.Series(site_clean), pd.Series(site_codes)

# Add primary site to your df_clean dataset
print("Step 1: Adding primary site transformation")
print("-" * 50)

# Transform primary site
df_clean['primary_site'], df_clean['site_code'] = transform_primary_site(df['Primary Site - labeled'])

# Ensure site_code is kept as string/object type
df_clean['site_code'] = df_clean['site_code'].astype('object')

print("Primary site distribution:")
site_counts = df_clean['primary_site'].value_counts()
for site, count in site_counts.items():
    pct = count / len(df_clean) * 100
    print(f"  {site:<12}: {count:>8,} ({pct:>5.1f}%)")

print("\nStep 2: Create CS analysis dataset with primary site")
print("-" * 50)

# Filter to CS era and add primary site
df_cs_with_site = df_clean[df_clean['has_cs_data'] == 1].copy()
df_cs_with_site = df_cs_with_site.dropna(subset=['survival_months'])
df_cs_with_site = df_cs_with_site[df_cs_with_site['survival_months'] > 0]

# Define variables including primary site
site_analysis_vars = [
    'age', 'survival_months', 'cancer_death',
    'tumor_size_mm', 'nodes_positive', 'primary_site'
]

# Create complete case dataset with site
df_cs_site_complete = df_cs_with_site.dropna(subset=site_analysis_vars)

print(f"CS dataset with site: {len(df_cs_site_complete):,} cases")
print(f"Variables: {site_analysis_vars}")

print("\nStep 3: Analyze differences across primary sites")
print("-" * 50)

print("Sample sizes by primary site:")
site_summary = df_cs_site_complete.groupby('primary_site').agg({
    'age': ['count', 'mean', 'std'],
    'tumor_size_mm': ['mean', 'std'],
    'nodes_positive': ['mean', 'std'],
    'cancer_death': ['sum', 'mean'],
    'survival_months': ['mean', 'std']
}).round(2)

# Flatten column names
site_summary.columns = ['_'.join(col).strip() for col in site_summary.columns]

print(f"\n{'Site':<12} {'N':<8} {'Age':<12} {'Tumor(mm)':<12} {'Nodes':<10} {'Deaths':<8} {'Death%':<8} {'Survival':<12}")
print("-" * 90)

for site in df_cs_site_complete['primary_site'].unique():
    site_data = df_cs_site_complete[df_cs_site_complete['primary_site'] == site]

    n = len(site_data)
    age_mean = site_data['age'].mean()
    tumor_mean = site_data['tumor_size_mm'].mean()
    nodes_mean = site_data['nodes_positive'].mean()
    deaths = site_data['cancer_death'].sum()
    death_rate = site_data['cancer_death'].mean() * 100
    survival_mean = site_data['survival_months'].mean()

    print(f"{site:<12} {n:<8,} {age_mean:<12.1f} {tumor_mean:<12.1f} {nodes_mean:<10.1f} {deaths:<8,} {death_rate:<8.1f} {survival_mean:<12.1f}")

print("\nStep 4: Statistical tests for differences")
print("-" * 50)

# Test for significant differences using ANOVA-like approach
from scipy import stats

sites = df_cs_site_complete['primary_site'].unique()
print("Testing for differences across sites:")

# Age differences
age_groups = [df_cs_site_complete[df_cs_site_complete['primary_site'] == site]['age'].values
              for site in sites]
age_f_stat, age_p = stats.f_oneway(*age_groups)
print(f"Age differences: F={age_f_stat:.2f}, p={age_p:.1e}")

# Tumor size differences
tumor_groups = [df_cs_site_complete[df_cs_site_complete['primary_site'] == site]['tumor_size_mm'].values
                for site in sites]
tumor_f_stat, tumor_p = stats.f_oneway(*tumor_groups)
print(f"Tumor size differences: F={tumor_f_stat:.2f}, p={tumor_p:.1e}")

# Nodes differences
nodes_groups = [df_cs_site_complete[df_cs_site_complete['primary_site'] == site]['nodes_positive'].values
                for site in sites]
nodes_f_stat, nodes_p = stats.f_oneway(*nodes_groups)
print(f"Lymph nodes differences: F={nodes_f_stat:.2f}, p={nodes_p:.1e}")

# Cancer death rate differences (Chi-square test)
from scipy.stats import chi2_contingency

death_crosstab = pd.crosstab(df_cs_site_complete['primary_site'],
                            df_cs_site_complete['cancer_death'])
chi2_stat, chi2_p, dof, expected = chi2_contingency(death_crosstab)
print(f"Cancer death rate differences: χ²={chi2_stat:.2f}, p={chi2_p:.1e}")

print("\nStep 5: Pairwise comparisons for significant differences")
print("-" * 50)

# Focus on the most common sites for detailed comparison
common_sites = df_cs_site_complete['primary_site'].value_counts().head(5).index.tolist()
print(f"Focusing on 5 most common sites: {common_sites}")

print(f"\nDetailed comparison of common sites:")
print(f"{'Site':<12} {'N':<8} {'Age':<8} {'Tumor':<8} {'Nodes':<8} {'Death%':<8}")
print("-" * 55)

site_stats = {}
for site in common_sites:
    site_data = df_cs_site_complete[df_cs_site_complete['primary_site'] == site]

    stats_dict = {
        'n': len(site_data),
        'age_mean': site_data['age'].mean(),
        'tumor_mean': site_data['tumor_size_mm'].mean(),
        'nodes_mean': site_data['nodes_positive'].mean(),
        'death_rate': site_data['cancer_death'].mean() * 100
    }
    site_stats[site] = stats_dict

    print(f"{site:<12} {stats_dict['n']:<8,} {stats_dict['age_mean']:<8.1f} {stats_dict['tumor_mean']:<8.1f} {stats_dict['nodes_mean']:<8.1f} {stats_dict['death_rate']:<8.1f}")

print("\nStep 6: Clinical significance assessment")
print("-" * 50)

# Calculate effect sizes between most different sites
print("Largest differences observed:")

# Find sites with biggest differences
age_diff = max([site_stats[site]['age_mean'] for site in common_sites]) - min([site_stats[site]['age_mean'] for site in common_sites])
tumor_diff = max([site_stats[site]['tumor_mean'] for site in common_sites]) - min([site_stats[site]['tumor_mean'] for site in common_sites])
nodes_diff = max([site_stats[site]['nodes_mean'] for site in common_sites]) - min([site_stats[site]['nodes_mean'] for site in common_sites])
death_diff = max([site_stats[site]['death_rate'] for site in common_sites]) - min([site_stats[site]['death_rate'] for site in common_sites])

print(f"Age range across sites: {age_diff:.1f} years")
print(f"Tumor size range: {tumor_diff:.1f} mm")
print(f"Lymph nodes range: {nodes_diff:.1f} nodes")
print(f"Death rate range: {death_diff:.1f} percentage points")

print("\nStep 7: Cox regression with and without primary site")
print("-" * 50)

# Create enriched sample including primary site
np.random.seed(42)
events_df = df_cs_site_complete[df_cs_site_complete['cancer_death'] == 1]
non_events_df = df_cs_site_complete[df_cs_site_complete['cancer_death'] == 0]

max_events = min(1500, len(events_df))
remaining_for_non_events = 5000 - max_events

sampled_events = events_df.sample(n=max_events, random_state=42)
sampled_non_events = non_events_df.sample(n=remaining_for_non_events, random_state=42)
df_subset_with_site = pd.concat([sampled_events, sampled_non_events]).sample(frac=1, random_state=42).reset_index(drop=True)

print(f"Analysis sample: {len(df_subset_with_site):,} cases, {df_subset_with_site['cancer_death'].sum():,} events")

# Cox regression without primary site
cph_base = CoxPHFitter()
base_vars = ['age', 'tumor_size_mm', 'nodes_positive', 'survival_months', 'cancer_death']
cph_base.fit(df_subset_with_site[base_vars], duration_col='survival_months', event_col='cancer_death')

print(f"\nModel 1 (without site): C-index = {cph_base.concordance_index_:.3f}")

# Create dummy variables for primary site (reference: UOQ - most common)
# Only include numeric/boolean columns for Cox regression
numeric_cols = ['age', 'survival_months', 'cancer_death', 'tumor_size_mm', 'nodes_positive']
df_for_dummies = df_subset_with_site[numeric_cols + ['primary_site']].copy()

df_subset_dummies = pd.get_dummies(df_for_dummies, columns=['primary_site'], prefix='site', drop_first=False)

# Remove the reference category (UOQ) to avoid multicollinearity
ref_col = 'site_UOQ'
if ref_col in df_subset_dummies.columns:
    df_subset_dummies = df_subset_dummies.drop(columns=[ref_col])

# Get site dummy columns
site_cols = [col for col in df_subset_dummies.columns if col.startswith('site_')]
site_vars = ['age', 'tumor_size_mm', 'nodes_positive'] + site_cols + ['survival_months', 'cancer_death']

# Cox regression with primary site
cph_site = CoxPHFitter()
cph_site.fit(df_subset_dummies[site_vars], duration_col='survival_months', event_col='cancer_death')

print(f"Model 2 (with site): C-index = {cph_site.concordance_index_:.3f}")

# Calculate improvement
c_index_improvement = cph_site.concordance_index_ - cph_base.concordance_index_
print(f"C-index improvement: {c_index_improvement:.4f}")

# Likelihood ratio test
from lifelines.statistics import logrank_test
lr_stat = -2 * (cph_base.log_likelihood_ - cph_site.log_likelihood_)
df_diff = len(site_cols)  # degrees of freedom difference

from scipy.stats import chi2
lr_p_value = 1 - chi2.cdf(lr_stat, df_diff)
print(f"Likelihood ratio test: LR = {lr_stat:.2f}, df = {df_diff}, p = {lr_p_value:.1e}")

print("\nStep 8: Site-specific hazard ratios")
print("-" * 50)

print("Hazard ratios for primary site (reference: UOQ):")
print(f"{'Site':<15} {'HR':<8} {'95% CI':<15} {'p-value':<10}")
print("-" * 50)

site_results = cph_site.summary
for col in site_cols:
    if col in site_results.index:
        site_name = col.replace('site_', '')
        hr = np.exp(site_results.loc[col, 'coef'])
        ci_low = np.exp(site_results.loc[col, 'coef lower 95%'])
        ci_high = np.exp(site_results.loc[col, 'coef upper 95%'])
        p_val = site_results.loc[col, 'p']

        p_str = f"{p_val:.1e}" if p_val < 0.001 else f"{p_val:.3f}"
        print(f"{site_name:<15} {hr:<8.2f} [{ci_low:.2f}-{ci_high:.2f}] {p_str:<10}")

# Simplified SEER Primary Site Analysis - Two Tables Only
import pandas as pd
import numpy as np
from lifelines import CoxPHFitter

def transform_primary_site(site_series):
    """Transform primary site to simplified categories"""
    site_clean = []
    for site in site_series:
        if 'Upper-outer quadrant' in site:
            site_clean.append('UOQ')
        elif 'Upper-inner quadrant' in site:
            site_clean.append('UIQ')
        elif 'Lower-outer quadrant' in site:
            site_clean.append('LOQ')
        elif 'Lower-inner quadrant' in site:
            site_clean.append('LIQ')
        elif 'Central portion' in site:
            site_clean.append('Central')
        elif 'Nipple' in site:
            site_clean.append('Nipple')
        elif 'Axillary tail' in site:
            site_clean.append('Axillary')
        elif 'Overlapping lesion' in site:
            site_clean.append('Overlapping')
        elif 'NOS' in site:
            site_clean.append('NOS')
        else:
            site_clean.append('Unknown')
    return pd.Series(site_clean)

# Data preparation
df_clean['primary_site'] = transform_primary_site(df['Primary Site - labeled'])
df_cs_with_site = df_clean[df_clean['has_cs_data'] == 1].copy()
df_cs_with_site = df_cs_with_site.dropna(subset=['survival_months'])
df_cs_with_site = df_cs_with_site[df_cs_with_site['survival_months'] > 0]

site_analysis_vars = ['age', 'survival_months', 'cancer_death', 'tumor_size_mm', 'nodes_positive', 'primary_site']
df_cs_site_complete = df_cs_with_site.dropna(subset=site_analysis_vars)

# TABLE 1: Primary Site Summary Statistics
site_table = []
total_n = len(df_cs_site_complete)

for site in df_cs_site_complete['primary_site'].unique():
    site_data = df_cs_site_complete[df_cs_site_complete['primary_site'] == site]
    n = len(site_data)

    site_table.append({
        'Site': site,
        'N': f"{n:,}",
        'Proportion (%)': round(n / total_n * 100, 1),
        'Age (Mean)': round(site_data['age'].mean(), 1),
        'Tumor Size (mm)': round(site_data['tumor_size_mm'].mean(), 1),
        'Positive Nodes': round(site_data['nodes_positive'].mean(), 1),
        'Deaths': f"{site_data['cancer_death'].sum():,}",
        'Death Rate (%)': round(site_data['cancer_death'].mean() * 100, 1),
        'Survival (months)': round(site_data['survival_months'].mean(), 1)
    })

table1 = pd.DataFrame(site_table).sort_values(by='Death Rate (%)', ascending=False).reset_index(drop=True)
print("TABLE 1: Primary Site Summary Statistics (Sorted by Death Rate)")
display(table1)

"""## CS Version

"""

# Assume df_clean is available from the original transformation
import pandas as pd
import numpy as np

print("="*80)
print("CREATING CS ERA ANALYSIS DATASET")
print("="*80)

print("Step 1: Filter to CS era patients only")
print("-" * 50)

# Start with full transformed dataset
n_total = len(df_clean)
print(f"Total transformed cases: {n_total:,}")

# Filter to CS era only (has_cs_data = 1)
df_cs = df_clean[df_clean['has_cs_data'] == 1].copy()
n_cs = len(df_cs)
print(f"CS era cases: {n_cs:,} ({n_cs/n_total*100:.1f}%)")

print("\nStep 2: Remove problematic survival data")
print("-" * 50)

# Remove missing survival time
initial_cs = len(df_cs)
df_cs = df_cs.dropna(subset=['survival_months'])
n_after_missing = len(df_cs)
print(f"After removing missing survival time: {n_after_missing:,} (removed: {initial_cs - n_after_missing:,})")

# Remove zero survival time
zero_survival = (df_cs['survival_months'] == 0).sum()
df_cs = df_cs[df_cs['survival_months'] > 0]
n_after_zero = len(df_cs)
print(f"Zero survival time cases removed: {zero_survival:,}")
print(f"After removing zero survival: {n_after_zero:,}")

print("\nStep 3: Remove EOD-related and redundant variables")
print("-" * 50)

# Define variables to keep for CS analysis
keep_variables = [
    # Core survival variables
    'age',
    'survival_months',
    'cancer_death',

    # Main staging variables (CS era)
    'tumor_size_mm',
    'has_cs_data',

    # Lymph node variables
    'nodes_positive',
    'nodes_positive_known',
    'nodes_examined',
    'nodes_examined_known',
    'nodes_data_complete',

    # Treatment timing
    'days_to_treatment',
    'treatment_timing_known',
    'primary_site'
]

# Create clean CS dataset with selected variables only
df_cs_clean = df_cs[keep_variables].copy()

print(f"Variables kept: {len(keep_variables)}")
print("Kept variables:")
for i, var in enumerate(keep_variables, 1):
    print(f"  {i:2d}. {var}")

print(f"\nRemoved variables (EOD-related and redundant):")
removed_vars = [
    't_stage', 'has_eod_data', 'era_cs', 'era_eod', 'vital_status'
]
for var in removed_vars:
    print(f"  - {var}")

print("\nStep 4: Analyze data quality in CS dataset")
print("-" * 50)

print(f"Final CS dataset shape: {df_cs_clean.shape}")
print(f"Cases: {len(df_cs_clean):,}")
print(f"Variables: {len(df_cs_clean.columns)}")

print(f"\nData completeness:")
for col in df_cs_clean.columns:
    missing = df_cs_clean[col].isna().sum()
    missing_pct = missing / len(df_cs_clean) * 100
    dtype = df_cs_clean[col].dtype
    print(f"  {col:<25} | {str(dtype):<7} | Missing: {missing:>6,} ({missing_pct:>5.1f}%)")

print("\nStep 5: Analyze key variables in CS dataset")
print("-" * 50)

# Age analysis
print(f"Age:")
print(f"  Range: {df_cs_clean['age'].min():.0f} - {df_cs_clean['age'].max():.0f} years")
print(f"  Mean: {df_cs_clean['age'].mean():.1f} years")

# Survival analysis
print(f"\nSurvival time:")
print(f"  Range: {df_cs_clean['survival_months'].min():.0f} - {df_cs_clean['survival_months'].max():.0f} months")
print(f"  Mean: {df_cs_clean['survival_months'].mean():.1f} months")
print(f"  Median: {df_cs_clean['survival_months'].median():.1f} months")

# Event analysis
cancer_deaths = df_cs_clean['cancer_death'].sum()
cancer_death_rate = df_cs_clean['cancer_death'].mean() * 100
print(f"\nCancer deaths: {cancer_deaths:,} ({cancer_death_rate:.1f}%)")

# Tumor size analysis
tumor_available = df_cs_clean['tumor_size_mm'].notna().sum()
print(f"\nTumor size data:")
print(f"  Cases with tumor size: {tumor_available:,} ({tumor_available/len(df_cs_clean)*100:.1f}%)")

if tumor_available > 0:
    tumor_data = df_cs_clean[df_cs_clean['tumor_size_mm'].notna()]
    print(f"  Tumor size range: {tumor_data['tumor_size_mm'].min():.0f} - {tumor_data['tumor_size_mm'].max():.0f} mm")
    print(f"  Tumor size mean: {tumor_data['tumor_size_mm'].mean():.1f} mm")
    print(f"  Tumor size median: {tumor_data['tumor_size_mm'].median():.1f} mm")

    # Tumor size categories (T-stage approximation)
    print(f"\nTumor size distribution (approximate T-stage):")
    print(f"  ≤20mm (≈T1): {(tumor_data['tumor_size_mm'] <= 20).sum():,} ({(tumor_data['tumor_size_mm'] <= 20).mean()*100:.1f}%)")
    print(f"  21-50mm (≈T2): {((tumor_data['tumor_size_mm'] > 20) & (tumor_data['tumor_size_mm'] <= 50)).sum():,} ({((tumor_data['tumor_size_mm'] > 20) & (tumor_data['tumor_size_mm'] <= 50)).mean()*100:.1f}%)")
    print(f"  >50mm (≈T3+): {(tumor_data['tumor_size_mm'] > 50).sum():,} ({(tumor_data['tumor_size_mm'] > 50).mean()*100:.1f}%)")

# Lymph node analysis
nodes_available = df_cs_clean['nodes_positive_known'].sum()
print(f"\nLymph node data:")
print(f"  Cases with node data: {nodes_available:,} ({nodes_available/len(df_cs_clean)*100:.1f}%)")

if nodes_available > 0:
    node_data = df_cs_clean[df_cs_clean['nodes_positive_known'] == 1]
    print(f"  Positive nodes range: {node_data['nodes_positive'].min():.0f} - {node_data['nodes_positive'].max():.0f}")
    print(f"  Positive nodes mean: {node_data['nodes_positive'].mean():.1f}")
    print(f"  Node-negative cases: {(node_data['nodes_positive'] == 0).sum():,} ({(node_data['nodes_positive'] == 0).mean()*100:.1f}%)")

# Treatment timing
treatment_available = df_cs_clean['treatment_timing_known'].sum()
print(f"\nTreatment timing:")
print(f"  Cases with treatment data: {treatment_available:,} ({treatment_available/len(df_cs_clean)*100:.1f}%)")

if treatment_available > 0:
    treatment_data = df_cs_clean[df_cs_clean['treatment_timing_known'] == 1]
    print(f"  Days to treatment range: {treatment_data['days_to_treatment'].min():.0f} - {treatment_data['days_to_treatment'].max():.0f}")
    print(f"  Days to treatment mean: {treatment_data['days_to_treatment'].mean():.1f}")

print("\nStep 6: Create analysis-ready subsets")
print("-" * 50)

# Complete case analysis (all key variables available)
complete_case_vars = ['age', 'survival_months', 'cancer_death', 'tumor_size_mm', 'nodes_positive']
df_cs_complete = df_cs_clean.dropna(subset=complete_case_vars)
print(f"Complete case analysis dataset: {len(df_cs_complete):,} cases ({len(df_cs_complete)/len(df_cs_clean)*100:.1f}%)")

# Core analysis (age + nodes, maximum sample)
core_vars = ['age', 'survival_months', 'cancer_death', 'nodes_positive']
df_cs_core = df_cs_clean.dropna(subset=core_vars)
print(f"Core analysis dataset (age + nodes): {len(df_cs_core):,} cases ({len(df_cs_core)/len(df_cs_clean)*100:.1f}%)")

# Tumor size analysis (age + tumor size)
tumor_vars = ['age', 'survival_months', 'cancer_death', 'tumor_size_mm']
df_cs_tumor = df_cs_clean.dropna(subset=tumor_vars)
print(f"Tumor size analysis dataset: {len(df_cs_tumor):,} cases ({len(df_cs_tumor)/len(df_cs_clean)*100:.1f}%)")

print("\nStep 7: Compare with EOD era")
print("-" * 50)

print(f"CS vs EOD era comparison:")
print(f"  CS era cases: {len(df_cs_clean):,}")
print(f"  CS complete cases: {len(df_cs_complete):,}")
print(f"  CS cancer death rate: {df_cs_clean['cancer_death'].mean()*100:.1f}%")
print(f"  CS mean survival: {df_cs_clean['survival_months'].mean():.1f} months")
print(f"  CS max survival: {df_cs_clean['survival_months'].max():.0f} months")

print(f"\nAdvantages of CS era data:")
print(f"  - Larger sample size")
print(f"  - Longer follow-up time")
print(f"  - Higher event rate (more deaths observed)")
print(f"  - Better for long-term survival analysis")

print("\nStep 8: Final dataset summary")
print("-" * 50)

print(f"""
CS ERA ANALYSIS DATASETS CREATED:

1. FULL CS DATASET (df_cs_clean):
   - Cases: {len(df_cs_clean):,}
   - Variables: {len(df_cs_clean.columns)}
   - Time period: 2004-2015 diagnoses
   - Use for: Descriptive analysis

2. COMPLETE CASE DATASET (df_cs_complete):
   - Cases: {len(df_cs_complete):,}
   - Variables: age, survival_months, cancer_death, tumor_size_mm, nodes_positive
   - Use for: Primary Cox regression analysis

3. CORE DATASET (df_cs_core):
   - Cases: {len(df_cs_core):,}
   - Variables: age, survival_months, cancer_death, nodes_positive
   - Use for: Maximum sample analysis

4. TUMOR-FOCUSED DATASET (df_cs_tumor):
   - Cases: {len(df_cs_tumor):,}
   - Variables: age, survival_months, cancer_death, tumor_size_mm
   - Use for: Tumor size effect analysis

RECOMMENDED ANALYSIS:
Use df_cs_complete for primary analysis - good balance of sample size and variables
""")

# Show sample of recommended dataset
print(f"\nSample of complete case dataset:")
print(df_cs_complete[complete_case_vars].head(10))

print(f"\nBasic statistics for complete case dataset:")
print(df_cs_complete[complete_case_vars].describe())

print(f"\nDatasets available for analysis:")
print(f"- df_cs_clean: Full CS dataset")
print(f"- df_cs_complete: Complete case analysis (RECOMMENDED)")
print(f"- df_cs_core: Core variables only")
print(f"- df_cs_tumor: Tumor-focused analysis")

"""### EOD Version

"""

print("="*80)
print("CREATING EOD ERA ANALYSIS DATASET")
print("="*80)

print("Step 1: Filter to EOD era patients only")
print("-" * 50)

# Start with full transformed dataset
n_total = len(df_clean)
print(f"Total transformed cases: {n_total:,}")

# Filter to EOD era only (has_eod_data = 1)
df_eod = df_clean[df_clean['has_eod_data'] == 1].copy()
n_eod = len(df_eod)
print(f"EOD era cases: {n_eod:,} ({n_eod/n_total*100:.1f}%)")

print("\nStep 2: Remove problematic survival data")
print("-" * 50)

# Remove missing survival time
df_eod = df_eod.dropna(subset=['survival_months'])
n_after_missing = len(df_eod)
print(f"After removing missing survival time: {n_after_missing:,}")

# Remove zero survival time (problematic for Cox models)
zero_survival = (df_eod['survival_months'] == 0).sum()
df_eod = df_eod[df_eod['survival_months'] > 0]
n_after_zero = len(df_eod)
print(f"Zero survival time cases removed: {zero_survival:,}")
print(f"After removing zero survival: {n_after_zero:,}")

print("\nStep 3: Remove CS-related and redundant variables")
print("-" * 50)

# Define variables to keep for EOD analysis
keep_variables = [
    # Core survival variables
    'age',
    'survival_months',
    'cancer_death',

    # Main staging variables (EOD era)
    't_stage',
    'has_eod_data',

    # Lymph node variables
    'nodes_positive',
    'nodes_positive_known',
    'nodes_examined',
    'nodes_examined_known',
    'nodes_data_complete',

    # Treatment timing
    'days_to_treatment',
    'treatment_timing_known',
    'primary_site'
]

# Create clean EOD dataset with selected variables only
df_eod_clean = df_eod[keep_variables].copy()

print(f"Variables kept: {len(keep_variables)}")
print("Kept variables:")
for i, var in enumerate(keep_variables, 1):
    print(f"  {i:2d}. {var}")

print(f"\nRemoved variables (CS-related and redundant):")
removed_vars = [
    'tumor_size_mm', 'has_cs_data', 'era_cs', 'era_eod', 'vital_status'
]
for var in removed_vars:
    print(f"  - {var}")

print("\nStep 4: Analyze data quality in EOD dataset")
print("-" * 50)

print(f"Final EOD dataset shape: {df_eod_clean.shape}")
print(f"Cases: {len(df_eod_clean):,}")
print(f"Variables: {len(df_eod_clean.columns)}")

print(f"\nData completeness:")
for col in df_eod_clean.columns:
    missing = df_eod_clean[col].isna().sum()
    missing_pct = missing / len(df_eod_clean) * 100
    dtype = df_eod_clean[col].dtype
    print(f"  {col:<25} | {str(dtype):<7} | Missing: {missing:>5,} ({missing_pct:>5.1f}%)")

print("\nStep 5: Analyze key variables in EOD dataset")
print("-" * 50)

# Age analysis
print(f"Age:")
print(f"  Range: {df_eod_clean['age'].min():.0f} - {df_eod_clean['age'].max():.0f} years")
print(f"  Mean: {df_eod_clean['age'].mean():.1f} years")

# Survival analysis
print(f"\nSurvival time:")
print(f"  Range: {df_eod_clean['survival_months'].min():.0f} - {df_eod_clean['survival_months'].max():.0f} months")
print(f"  Mean: {df_eod_clean['survival_months'].mean():.1f} months")
print(f"  Median: {df_eod_clean['survival_months'].median():.1f} months")

# Event analysis
cancer_deaths = df_eod_clean['cancer_death'].sum()
cancer_death_rate = df_eod_clean['cancer_death'].mean() * 100
print(f"\nCancer deaths: {cancer_deaths:,} ({cancer_death_rate:.1f}%)")

# T-stage analysis
print(f"\nT-stage distribution:")
t_stage_counts = df_eod_clean['t_stage'].value_counts().sort_index()
for stage, count in t_stage_counts.items():
    if pd.notna(stage):
        pct = count / len(df_eod_clean) * 100
        stage_name = ['Tis', 'T1', 'T2', 'T3', 'T4'][int(stage)]
        print(f"  {stage_name} (stage {int(stage)}): {count:,} ({pct:.1f}%)")

t_stage_missing = df_eod_clean['t_stage'].isna().sum()
print(f"  Missing T-stage: {t_stage_missing:,} ({t_stage_missing/len(df_eod_clean)*100:.1f}%)")

# Lymph node analysis
nodes_available = df_eod_clean['nodes_positive_known'].sum()
print(f"\nLymph node data:")
print(f"  Cases with node data: {nodes_available:,} ({nodes_available/len(df_eod_clean)*100:.1f}%)")

if nodes_available > 0:
    node_data = df_eod_clean[df_eod_clean['nodes_positive_known'] == 1]
    print(f"  Positive nodes range: {node_data['nodes_positive'].min():.0f} - {node_data['nodes_positive'].max():.0f}")
    print(f"  Positive nodes mean: {node_data['nodes_positive'].mean():.1f}")
    print(f"  Node-negative cases: {(node_data['nodes_positive'] == 0).sum():,} ({(node_data['nodes_positive'] == 0).mean()*100:.1f}%)")

print("\nStep 6: Create analysis-ready subsets")
print("-" * 50)

# Complete case analysis (all key variables available)
complete_case_vars = ['age', 'survival_months', 'cancer_death', 't_stage', 'nodes_positive']
df_eod_complete = df_eod_clean.dropna(subset=complete_case_vars)
print(f"Complete case analysis dataset: {len(df_eod_complete):,} cases ({len(df_eod_complete)/len(df_eod_clean)*100:.1f}%)")

# Core analysis (age + nodes, maximum sample)
core_vars = ['age', 'survival_months', 'cancer_death', 'nodes_positive']
df_eod_core = df_eod_clean.dropna(subset=core_vars)
print(f"Core analysis dataset (age + nodes): {len(df_eod_core):,} cases ({len(df_eod_core)/len(df_eod_clean)*100:.1f}%)")

print("\nStep 7: Final dataset summary")
print("-" * 50)

print(f"""
EOD ERA ANALYSIS DATASETS CREATED:

1. FULL EOD DATASET (df_eod_clean):
   - Cases: {len(df_eod_clean):,}
   - Variables: {len(df_eod_clean.columns)}
   - Time period: 2018+ diagnoses
   - Use for: Descriptive analysis, missing data patterns

2. COMPLETE CASE DATASET (df_eod_complete):
   - Cases: {len(df_eod_complete):,}
   - Variables: age, survival_months, cancer_death, t_stage, nodes_positive
   - Use for: Primary Cox regression analysis

3. CORE DATASET (df_eod_core):
   - Cases: {len(df_eod_core):,}
   - Variables: age, survival_months, cancer_death, nodes_positive
   - Use for: Maximum sample analysis if T-stage has too much missing data

RECOMMENDED NEXT STEPS:
1. Descriptive statistics and plots
2. Cox proportional hazards regression
3. Survival curves by T-stage
4. Model diagnostics and validation
""")

# Show sample of recommended dataset
print(f"\nSample of complete case dataset:")
print(df_eod_complete[complete_case_vars].head(10))

print(f"\nBasic statistics for complete case dataset:")
print(df_eod_complete[complete_case_vars].describe())

# Save the datasets with descriptive names
print(f"\nDatasets available for analysis:")
print(f"- df_eod_clean: Full EOD dataset")
print(f"- df_eod_complete: Complete case analysis")
print(f"- df_eod_core: Core variables only")

"""## EDA"""

# Display df_cs_complete dataset details
import pandas as pd
import numpy as np

print("="*80)
print("DF_CS_COMPLETE DATASET DISPLAY")
print("="*80)

print("Step 1: Basic dataset information")
print("-" * 50)

print(f"Dataset shape: {df_cs_complete.shape}")
print(f"Total cases: {len(df_cs_complete):,}")
print(f"Total variables: {len(df_cs_complete.columns)}")

print(f"\nColumn names:")
for i, col in enumerate(df_cs_complete.columns, 1):
    print(f"  {i:2d}. {col}")

print("\nStep 2: First 10 rows of complete dataset")
print("-" * 50)

# Show the first 10 rows
print("df_cs_complete.head(10):")
print(df_cs_complete.head(10))

print("\nStep 3: Analysis variables specifically")
print("-" * 50)

# Focus on the 5 core analysis variables
analysis_vars = ['age', 'survival_months', 'cancer_death', 'tumor_size_mm', 'nodes_positive']
print(f"Core analysis variables: {analysis_vars}")
print(f"\nFirst 15 rows of analysis variables:")
print(df_cs_complete[analysis_vars].head(15))

print("\nStep 4: Data types and missing values check")
print("-" * 50)

print("Data types and NA count:")
for var in analysis_vars:
    dtype = df_cs_complete[var].dtype
    na_count = df_cs_complete[var].isna().sum()
    unique_count = df_cs_complete[var].nunique()
    print(f"  {var:<20}: {str(dtype):<8} | NA: {na_count:>6,} | Unique: {unique_count:>6,}")

print("\nStep 5: Summary statistics")
print("-" * 50)

print("Summary statistics for analysis variables:")
print(df_cs_complete[analysis_vars].describe())

print("\nStep 6: Value ranges and distributions")
print("-" * 50)

for var in analysis_vars:
    if var == 'cancer_death':
        # Binary variable
        counts = df_cs_complete[var].value_counts().sort_index()
        print(f"{var}:")
        for val, count in counts.items():
            pct = count / len(df_cs_complete) * 100
            status = "Event" if val == 1 else "Censored"
            print(f"  {val} ({status}): {count:,} ({pct:.1f}%)")
    else:
        # Continuous variables
        print(f"{var}:")
        print(f"  Min: {df_cs_complete[var].min():.1f}")
        print(f"  Max: {df_cs_complete[var].max():.1f}")
        print(f"  Mean: {df_cs_complete[var].mean():.1f}")
        print(f"  Median: {df_cs_complete[var].median():.1f}")

        if var == 'nodes_positive':
            # Show node distribution
            node_neg = (df_cs_complete[var] == 0).sum()
            node_1_3 = ((df_cs_complete[var] >= 1) & (df_cs_complete[var] <= 3)).sum()
            node_4_9 = ((df_cs_complete[var] >= 4) & (df_cs_complete[var] <= 9)).sum()
            node_10_plus = (df_cs_complete[var] >= 10).sum()

            print(f"    0 nodes: {node_neg:,} ({node_neg/len(df_cs_complete)*100:.1f}%)")
            print(f"    1-3 nodes: {node_1_3:,} ({node_1_3/len(df_cs_complete)*100:.1f}%)")
            print(f"    4-9 nodes: {node_4_9:,} ({node_4_9/len(df_cs_complete)*100:.1f}%)")
            print(f"    10+ nodes: {node_10_plus:,} ({node_10_plus/len(df_cs_complete)*100:.1f}%)")

        elif var == 'tumor_size_mm':
            # Show tumor size distribution
            t1 = ((df_cs_complete[var] > 0) & (df_cs_complete[var] <= 20)).sum()
            t2 = ((df_cs_complete[var] > 20) & (df_cs_complete[var] <= 50)).sum()
            t3_plus = (df_cs_complete[var] > 50).sum()

            print(f"    ≤20mm (≈T1): {t1:,} ({t1/len(df_cs_complete)*100:.1f}%)")
            print(f"    21-50mm (≈T2): {t2:,} ({t2/len(df_cs_complete)*100:.1f}%)")
            print(f"    >50mm (≈T3+): {t3_plus:,} ({t3_plus/len(df_cs_complete)*100:.1f}%)")

print("\nStep 7: Sample of diverse cases")
print("-" * 50)

print("Sample of different case types:")

# Show some diverse examples
print("\nYoung patients (age < 40):")
young = df_cs_complete[df_cs_complete['age'] < 40][analysis_vars].head(3)
print(young)

print("\nLarge tumors (>50mm):")
large_tumors = df_cs_complete[df_cs_complete['tumor_size_mm'] > 50][analysis_vars].head(3)
print(large_tumors)

print("\nMany positive nodes (>10):")
many_nodes = df_cs_complete[df_cs_complete['nodes_positive'] > 10][analysis_vars].head(3)
print(many_nodes)

print("\nEvent cases (cancer deaths):")
events = df_cs_complete[df_cs_complete['cancer_death'] == 1][analysis_vars].head(3)
print(events)

print("\n" + "="*80)
print("SUMMARY: df_cs_complete is ready for Cox regression!")
print("Variables: age + tumor_size_mm + nodes_positive")
print("Time: survival_months, Event: cancer_death")
print("="*80)

"""### 2 group version"""

# Extract UIQ and NOS groups for comparison
def filter_extreme_sites(df):
   """Filter to only UIQ and NOS cases"""
   uiq_cases = df[df['primary_site'] == 'C50.2-Upper-inner quadrant of breast']
   nos_cases = df[df['primary_site'] == 'C50.9-Breast, NOS']
   return pd.concat([uiq_cases, nos_cases])

# Apply filter to CS complete dataset
df_cs_complete_filtered = filter_extreme_sites(df_cs_complete)

print(f"Original CS complete: {len(df_cs_complete):,} cases")
print(f"UIQ + NOS filtered: {len(df_cs_complete_filtered):,} cases")
print(f"UIQ cases: {(df_cs_complete_filtered['primary_site'] == 'C50.2-Upper-inner quadrant of breast').sum():,}")
print(f"NOS cases: {(df_cs_complete_filtered['primary_site'] == 'C50.9-Breast, NOS').sum():,}")

"""## Save file"""

df_cs_complete.to_csv('seer_breast_analysis_ready.csv', index=False)
df_cs_complete_filtered.to_csv('seer_breast_analysis_filtered.csv', index=False)